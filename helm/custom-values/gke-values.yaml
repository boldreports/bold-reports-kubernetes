# Default values for boldreports.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
namespace: bold-services
appBaseUrl: ''
optionalLibs: 'mysql,oracle,postgresql,snowflake'
clusterProvider: 'gke'

persistentVolume:
  # persistent volumes were global resources. 
  # so if you already have Bold Reports installed in your cluster, then the previous persistent volume name will conflict with current installation.
  # Change this name to avoid conflicts with previous Bold Reports persistent volumes.
  name: bold-services-fileserver
  capacity: 3Gi
  gke:
    fileShareName: ''
    fileShareIp: ''

image:
  idrepo: us-docker.pkg.dev/boldreports/v9-1-7
  reportsRepo: us-docker.pkg.dev/boldreports/v9-1-7
  # Overrides the image tag whose default is the chart appVersion.
  idTag: 9.1.7
  reportsTag: 9.1.7
  pullPolicy: IfNotPresent
imagePullSecrets: []

loadBalancer:
  type: nginx
  affinityCookie:
    enable: true
    affinityCookieExpiration: 600
  # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
  # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
  # ingressClassName: nginx

  nginxIngressAnnotations:
    # Enter annotations here for adding annotations in nginx ingress
    # Example:
    # cert-manager.io/cluster-issuer: letsencrypt-prod
    # nginx.ingress.kubernetes.io/rewrite-target: /

  kongIngressAnnotations:
    # Enter annotations here for adding annotations in Kong ingress
    # Example:
    # konghq.com/preserve-host: "true"
    # konghq.com/protocols: "http,https"

  singleHost: 
    secretName: bold-tls
  # multipleHost:
    # hostArray:
      # - hosts: 
          # - kubernetes.docker.internal
          # - example.com
        # secretName: bold-tls

instanceConfig:
  - app: id-web
    replicaCount: 1
    minReplicas: 1
    maxReplicas: 20
    cpuResourceRequests: 250m
    memoryResourceRequests: 750Mi
  - app: id-api
    replicaCount: 1
    minReplicas: 1
    maxReplicas: 20
    cpuResourceRequests: 250m
    memoryResourceRequests: 750Mi
  - app: id-ums
    replicaCount: 1
    minReplicas: 1
    maxReplicas: 20
    cpuResourceRequests: 250m
    memoryResourceRequests: 750Mi
  - app: reports-web
    replicaCount: 1
    minReplicas: 1
    maxReplicas: 20
    cpuResourceRequests: 250m
    memoryResourceRequests: 750Mi
  - app: reports-api
    replicaCount: 1
    minReplicas: 1
    maxReplicas: 20
    cpuResourceRequests: 250m
    memoryResourceRequests: 750Mi
  - app: reports-jobs
    replicaCount: 1
    minReplicas: 1
    maxReplicas: 1
    cpuResourceRequests: 250m
    memoryResourceRequests: 750Mi
  - app: reports-reportservice
    replicaCount: 1
    minReplicas: 1
    maxReplicas: 1
    cpuResourceRequests: 250m
    memoryResourceRequests: 750Mi
  - app: reports-viewer
    replicaCount: 1
    minReplicas: 1
    maxReplicas: 20
    cpuResourceRequests: 250m
    memoryResourceRequests: 750Mi
  - app: bold-etl
    replicaCount: 1
    minReplicas: 1
    maxReplicas: 20
    cpuResourceRequests: 250m
    memoryResourceRequests: 750Mi

autoscaling:
  enabled: true
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80
  behavior:
    stabilizationWindowSeconds: 60
    podsValue: 1
    podsPeriodSeconds: 60
    percentValue: 10
    percentPeriodSeconds: 60

# Tolerations allow the pods to be scheduled into nodes with matching taints.
# Set this to true if you use tolerations in your cluster.
# If you need more than one toleration, you can add tolerations below.
tolerationEnable: false 
tolerations:
  - key: ""
    operator: ""
    value: ""
    effect: ""

# Node affinity ensures that the pods are scheduled into nodes with matching labels.
# Set this to true if you use Node affinity in your cluster.
nodeAffinityEnable: false
nodeAffinity:
  key: ""
  operator: ""
  value: ""

# Pod affinity ensures that the pods are scheduled into nodes with matching pods.
# Set this to true if you use pod Affinity in your cluster.
podAffinityEnable: false

# Pod anti-affinity ensures that the pods are not scheduled into nodes with matching pods.
# Set this to true if you use pod AntiAffinity in your cluster.
podAntiAffinityEnable: false